<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>机器学习 on Jason Han&#39;s Blog</title>
    <link>https://drjasonhan.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 机器学习 on Jason Han&#39;s Blog</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-gb</language>
    <lastBuildDate>Fri, 20 Nov 2020 18:25:18 +0800</lastBuildDate><atom:link href="https://drjasonhan.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>理解 Softmax</title>
      <link>https://drjasonhan.github.io/post/%E7%90%86%E8%A7%A3softmax/</link>
      <pubDate>Fri, 20 Nov 2020 18:25:18 +0800</pubDate>
      
      <guid>https://drjasonhan.github.io/post/%E7%90%86%E8%A7%A3softmax/</guid>
      <description>在机器学习尤其是深度学习中，Softmax 是个非常常用而且比较重要的函数，尤其在多分类的场景中使用广泛。通常，Softmax 函数被置于最后一个全连接层之后，把全连接层的输出映射为 0-1 之间的实数，并且归一化保证和为 1。
1. Softmax 定义 $$S(a):\left[\begin{matrix} a_1	\\ a_2	\\ \cdots \\ a_N \end{matrix} \right]\rightarrow \left[\begin{matrix}S_1 \\ S_2 \\ \cdots \\ S_N \end{matrix} \right] \tag{1}$$$$S_i=\frac{e^{a_j}}{\sum_{k=1}^{N}e^{a_k}} \tag{2}$$## 2. 为什么要使用 SoftmaxSoftmax 函数主要用于分类，与之对应的我们姑且称之为 Hardmax。对于一个分类结果，如 $$ [1,2,3] $$ 如果使用 Hardmax，那就意味着选出的是其中的最大值，即3；而 Softmax 则是以一定的概率选出最终的值，根据公式(2)，上面三个值得概率分别为： $$ [0.09, 0.24, 0.67] $$ 相对于 Softmax，Hardmax 在进行梯度计算时有着明显的缺陷：只有在被选中的那个变量上面才有梯度，其他都是没有的。Softmax 则不存在这一问题，具体的梯度求解公式可见下一节。
其实，最常拿来与 Softmax 比较的不是 Hardmax，而是标准的归一化方法，即将所有输出值分别处以这些值的总和。根据这种方法，上面的结果的到的三个概率为： $$ [0.17, 0.33, 0.50] $$ 至于为什么 Softmax 更好，参考文献 1,2中各路大神讲解的较为深入。就个人理解而言，其主要原因在于平衡概率分布3以及配合交叉熵使用。</description>
    </item>
    
    <item>
      <title>重新理解MLE，MAP和贝叶斯估计</title>
      <link>https://drjasonhan.github.io/post/%E7%90%86%E8%A7%A3mlemap%E5%92%8C%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/</link>
      <pubDate>Sun, 25 Oct 2020 11:46:18 +0800</pubDate>
      
      <guid>https://drjasonhan.github.io/post/%E7%90%86%E8%A7%A3mlemap%E5%92%8C%E8%B4%9D%E5%8F%B6%E6%96%AF%E4%BC%B0%E8%AE%A1/</guid>
      <description>1. MLE，极大似然估计 MLE把带估计的参数看做确定的量，其目标函数是使得以观察到的样本的概率最大： $$ \operatorname{argmax}p(X \mid \theta)=\operatorname{argmax}\prod_{x_1}^{x_n} p(x_i \mid \theta) \tag{1} $$ 对数化处理后为： $$ \operatorname{argmax}\prod_{x_1}^{x_n} p(x_i \mid \theta)=\operatorname{argmax}\sum_{x_1}^{x_n} \log p(x_i \mid \theta) \tag{2} $$ 即：
$$\left\{\begin{aligned}&amp;L(\theta) = \sum_{x_1}^{x_n} \log p(x_i \mid \theta)\\&amp;\frac{\partial L}{\partial \theta} =0\\\end{aligned} \right. \tag{3}$$2. MAP，最大后验估计 MAP寻求的是能使后验概率$ P(\theta \mid X) $最大的 $ \theta $ 值:
$$\begin{aligned}\operatorname{argmax}p(\theta \mid X) &amp;=\operatorname{argmax} \frac{p(X \mid \theta) p(\theta)}{p(X)} \\&amp;=\operatorname{argmax}p(X \mid \theta) p(\theta)\\&amp;=\operatorname{argmax}\left(\prod_{x_1}^{x_n} p(x_i \mid \theta)\right) p(\theta)\end{aligned} \tag{4}\$$省略$P(X)$是因为$X$与$\theta$无关。对数化处理后，上式可表达为：$$\operatorname{argmax}\left(\sum_{x_1}^{x_n} \log p(x_i \mid \theta)+\log p(\theta)\right) \tag{5}\$$相比于式（2），式（4）仅仅是多了一项 $p(\theta)$ ，这就是参数$\theta$的先验分布 。在实际中，当人们已经接受或知道的普遍的规律时，可以对预先给出这一规律。比如在扔硬币的试验中，每次抛出正面发生的概率应该服从一个概率分布，且基本在0.</description>
    </item>
    
  </channel>
</rss>
